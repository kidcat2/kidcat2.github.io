---
title: "[News] CGW : SIGGRAPH 2024 주요 발표"
date: 2025-01-31 +0000
categories: [Computer Graphics]
tags: [Computer Graphics, CGW, SIGGRAPH2024, News]
math: true
toc: true
published : true
---

# CGW(Computer Graphics World) Article 

`Source` 
| [SIGGRAPH 2024 shapes the future of computer graphics with immersive tech and cutting-edge demos](https://www.cgw.com/Press-Center/Siggraph/2024/SIGGRAPH-2024-shapes-the-future-of-computer-grap.aspx)

---

> CGW(Computer Graphics World)에서 24년 7월 10일 작성된 SIGGRAPH 2024를 소개하는 기사입니다.
{: .prompt-info }

**SIGGRAPH 2024** 에서는 `Talks`, `Courses`, `Panels`, `Appy` `Hour`, `Immersive Pavilion`, `Real-Time Live` 등 게임과 연계된 최신 기술들이 발표되었습니다.

`Immersive Pavilion`과 `Real-Time Live`는 SIGGRAPH의 독특한 행사입니다.

## **Talk**

`Talk` 세션에서는 `Natalya Tatarchuk`의 **Advances in Real-Time Rendering in Games Part 1,2**가 진행되었습니다.

Video Game의 가상 세계를 **fast, interactive** 하게 렌더링하는 최신 기술과 시연이 있었다고 합니다. [^ref1]

`Natalya Tatarchuk`는 Unity에서 Chief Architect를 맡고 있습니다.[^ref2]

`Course`, `Pannels`, `Appy Hour`에서는 추가적인 강좌, 발표, 토론, 기술 시연 및 체험이 진행되었습니다. 기사에서는 크게 언급이 없습니다.

## **Real-Time Live**

Real-Time Live는 모든 발표가 **사전 녹화 없이, 슬라이드 없이, 6분 이내에 실시간으로 진행**됩니다. 

행사는 약 2시간 동안 진행되었으며, 전체 영상은 [여기](https://www.youtube.com/watch?v=Gm1B5DT8kE0)에서 확인할 수 있습니다

기사에서는 3가지 주요 발표를 언급합니다.

<br>

1. **MOVIN TRACIN': Move Outside the Box**

    *MOVIN*은 단일 LiDAR 센서만을 사용한 `실시간 자유형 신체 모션 캡쳐(real-time free-body motion capture AI)` 기술입니다. 

    0.1초의 짧은 지연시간에 `3D 모션`을 정확하게 추적하고 자동 보정(Auto-Calibration) 합니다.

    이는 `multiplay gaiming`에서 혁신적인 기술이 될 것이라고 이야기 합니다.

    [영상](https://www.youtube.com/watch?v=C0o8Hz4FFTk)
    
    <br>

2. **Enhancing Narratives with SayMotion's text-to-3D animation and LLMs**

    `SayMotion`은 **text-to 3D Animation** 플랫폼입니다.

    `LLM(Large Language Model)`과 `Physics Simulation`을 활용해 text를 3D human motion으로 변환합니다.

   `prompt optimization`과 `AI Inpainting` 기술을 적용해 XR, Game 등의 다양한 3D Human motion 작업에 활용될 수 있습니다.

    [영상](https://www.youtube.com/watch?v=-XQ_AinQYng)

    <br>

3. **Revolutionizing VFX Production with Real-Time Volumetric Effects**

    `Zibra AI`는 표준 하드웨어에서도 높은 품질의 `실시간 volumetric visual effects(VFX)` 를 생성합니다.

    `ZibraVDB compression technology`, `Zibra Effects real-time simulation tools` 등 다양한 작업을 소개합니다.

    [영상](https://www.youtube.com/watch?v=c8FQ_jidNH0)

    <br>

## **Immersive Pavilion(몰입형 파빌리온)**

`Immersive Pavilion`은 Game, AR, VR, MR, interactive projection mapping, multi-sensory technologies 등 다양한 기술을 체험할 수 있는 공간입니다.

체험을 통해 참가자(후원자)들은 social experience, game, artistic expression에 대해 자유롭게 논의하고 토론합니다.

`Real-Time Live`이 기술을 시연하는 느낌이라면, `Immersive Pavilion`은 기술들을 직접 체험해본다고 생각하시면 좋을 것 같습니다.

마찬가지로 기사에서는 3가지 주요 발표를 소개하고 있습니다.

<br>

1. **MOFA: Multiplayer Onsite Fighting Arena**
    
    `Reality Design`은 HoloKit X 헤드셋을 사용해 혼합현실에서(Mixed Reality) 동시적(sychronous)이고 비대칭적인(asymmetric) 신체 상호 작용(bodily interplay)을 탐험합니다. 

    기사에서 말하는 sychronous assymmetric bodily interplay 이란 표현을 잘 이해하지 못했습니다. 

    데모 영상을 보면, *VR을 사용하는 Player A*와 *iPhne을 사용하는 Player B*가 같이 플레이 하는 모습을 볼 수 있습니다.

    제가 생각하기로 `비대칭적인`은 서로 다른 장치를 사용해 플레이하는 것을 말하고, `동시적`은 다른 장치를 사용함에도 같은 게임을 실시간으로 같이 즐길 수 있다는 것을 의미하는 것 같습니다.

    [Demo](https://mofa.ar/)

    <br>

2. **Metapunch X: Combing Multidisplay and Exertion Interaction for Watching and Playing E-sports in Multiverse**

    `MetaPunch X`는 Multi-display 관전 기능과 XR 신체 상호작용( exertion interaction)을 통합한 체험형 햅틱(haptic) 피드백 E-sports 게임입니다.

    `햅틱 피드백(Haptic Feedback)`은 게임 속 상호작용을 사용자에게 하드웨어를 통해 진동, 압력 등을 전달함으로써 실제 감각 처럼 느끼게 하는 것을 말하는 것 같습니다.

    `XR Head-mounted Display`와 로봇을 활용해 몰임갑을 증가시킨다고 합니다.

    [Demo](https://www.youtube.com/watch?v=pfZ-DYSB5hw)

    <br>

3. **Reframe: Recording and Editing Character Motion in Virtual Reality**

    `Reframe`은 VR 환경에서 3D 애니메이션을 제작합니다.

    사용자의 full body motion, 얼굴 표정, 손동작 등을 VR Tracking을 통해 기록할 뿐 아니라, 실시간으로 기록물을 보고 조작해 편집할 수 있습니다. 

    [Demo](https://www.youtube.com/watch?v=FPCALjiO2HQ)

    <br>

## **마무리하며**

Derek Ham의 말 "우리들은 현재 e-sports를 모니터와 노트북으로 시청하지만, `Immersive action`은 그 다음이다." 이 제일 인상 깊었습니다.

이 문장은 `SIGGRAPH가` 지향하는 미래 방향성을 보여주는 듯 합니다. 

단순히 기술을 발표하는 것이 아니라, 게임과 그래픽 기술이 실생활 속에서 어떻게 확장되고 몰입형 경험을 제공할 것인가에 대한 비전을 제시하고 있습니다.

추후 기회가 된다면 `SIGGRAPH2024`에서 발표된 논문 및 흥미로운 영상들을 분석해보겠습니다.

### **References**

[^ref1]: [Advances in Real-Time Rendering in Games](https://advances.realtimerendering.com/)

[^ref2]: [Natalya Tatarchuk](https://cesium.com/guests/natalya-tatarchuk/)